{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PDB-CAT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **You have the option to explore the code in the following two cells or jump directly into the main code. In the main code section, you should identify and determine the necessary variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pdbecif.mmcif_io import CifFileReader\n",
    "from pdbecif.mmcif_tools import MMCIF2Dict\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from Bio.Align import PairwiseAligner \n",
    "from Bio.PDB import * \n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_blacklist(blacklist_path):\n",
    "\n",
    "    with open(blacklist_path, 'r') as f:\n",
    "        linea = f.read()\n",
    "    linea=linea.replace(' ','')\n",
    "    blacklist = linea.strip('\\n').split(',')\n",
    "\n",
    "    return blacklist\n",
    "\n",
    "\n",
    "def search_asym_id(cif_data,entity_id):\n",
    "    \"\"\" \n",
    "    From _entity_id we search the _struct_asym.id.\n",
    "    The _struct_asym.id is also the chain or subunit.\n",
    "    \"\"\"\n",
    "\n",
    "    asym_id=[]\n",
    "    if '_struct_asym' in cif_data:\n",
    "        for r in cif_data._struct_asym.search('entity_id',entity_id).values():\n",
    "            asym_id.append(r['id'])\n",
    "        asym_id=','.join(asym_id)\n",
    "\n",
    "    return asym_id\n",
    "\n",
    "\n",
    "def search_peptide_code(cif_data,asym_id):\n",
    "    \"\"\"\n",
    "    Data items in the PDBX_MOLECULE category identify reference molecules within a PDB entry.\n",
    "    The value of _pdbx_molecule.prd_id is the PDB accession code for this reference molecule.\n",
    "    \"\"\"\n",
    "\n",
    "    pep_code=''\n",
    "    if '_pdbx_molecule' in cif_data:\n",
    "        for r in cif_data._pdbx_molecule.search('asym_id',asym_id).values():\n",
    "            pep_code=r['prd_id']\n",
    "        return pep_code\n",
    "    \n",
    "\n",
    "def search_ligand_code(cif_data, entity_id):\n",
    "    \"\"\"\n",
    "    From the entity_id we search _pdbx_entity_nonpoly.comp_id which is a pointer to the _chem_comp.id\n",
    "    \"\"\"\n",
    "\n",
    "    comp_id=''\n",
    "    if '_pdbx_entity_nonpoly' in cif_data:\n",
    "        for r in cif_data._pdbx_entity_nonpoly.search('entity_id',entity_id).values():\n",
    "            comp_id=r['comp_id']\n",
    "        return comp_id\n",
    "    \n",
    "    \n",
    "def check_polypeptide(cif_data, entity_id):\n",
    "    \"\"\"\n",
    "    Check if the polymer is a 'polypeptide(L)'. Only polypeptides are considered as the main polymers\n",
    "    Data items in the ENTITY_POLY category record details about the polymer, such as the type of the polymer, \n",
    "    the number of monomers and whether it has nonstandard features.\n",
    "    _entity_poly.type contains the type of the polymer. It can be: cyclic-pseudo-peptide, other, peptide nucleic acid, \n",
    "    polydeoxyribonucleotide, polydeoxyribonucleotide/polyribonucleotide hybrid, polypeptide(D), polypeptide(L), polyribonucleotide,\n",
    "    polysaccharide(D), polysaccharide(L).\n",
    "    \"\"\"\n",
    "\n",
    "    if '_entity_poly' in cif_data:\n",
    "        for r in cif_data._entity_poly.search('entity_id',entity_id).values():\n",
    "            if r['type'] == 'polypeptide(L)':\n",
    "                return 'Yes'\n",
    "            else:\n",
    "                return 'No'\n",
    "            \n",
    "            \n",
    "def check_covalent(cif_data,asym_id): \n",
    "    \"\"\"\n",
    "    Check if the ligand has a covalent bond with the protein\n",
    "    \"\"\"\n",
    "\n",
    "    if '_struct_conn' in cif_data:\n",
    "        for r in cif_data._struct_conn.search('conn_type_id','covale').values(): \n",
    "            if r['ptnr2_label_asym_id'] == asym_id and r['ptnr2_label_asym_id'] != r['ptnr1_label_asym_id']: # Millorar i comprovar que l'altre asym_id es de la proteina\n",
    "                return r['ptnr1_label_comp_id']+r['ptnr1_auth_seq_id'] # abans ptnr1_label_seq_id\n",
    "            if r['ptnr1_label_asym_id'] == asym_id and r['ptnr2_label_asym_id'] != r['ptnr1_label_asym_id']:\n",
    "                return r['ptnr2_label_comp_id']+r['ptnr2_auth_seq_id'] # abans ptnr2_label_seq_id\n",
    "\n",
    "def search_peptide_seq_one_letter_code(cif_data,entity_id):\n",
    "    if '_entity_poly' in cif_data:\n",
    "        for r in cif_data._entity_poly.search('entity_id',entity_id).values():\n",
    "            seq_one_letter_code = r['pdbx_seq_one_letter_code'] \n",
    "            \n",
    "        return seq_one_letter_code\n",
    "    \n",
    "    \n",
    "def search_peptide_seq_one_letter_code_can(cif_data,entity_id):\n",
    "    \"\"\"\n",
    "    Search standard-residue one letter sequence\n",
    "    \"\"\"\n",
    "    if '_entity_poly' in cif_data:\n",
    "        for r in cif_data._entity_poly.search('entity_id',entity_id).values():\n",
    "            seq_one_letter_code_can = ''.join(r['pdbx_seq_one_letter_code_can'].splitlines())\n",
    "            \n",
    "        return seq_one_letter_code_can\n",
    "    \n",
    "\n",
    "def search_for_mutation(reference_seq, one_letter_seq):\n",
    "    \"\"\" \n",
    "    Search for mutations, where is the mismatch, how many gaps there are and the identity of the sequence\n",
    "    \"\"\"\n",
    "\n",
    "    # Define aligner variables from PairwiseAligner\n",
    "    aligner = PairwiseAligner()\n",
    "    aligner.mode = 'global'\n",
    "    aligner.match_score = 5\n",
    "    aligner.mismatch_score = -3\n",
    "    aligner.open_gap_score = -7\n",
    "    aligner.extend_gap_score = -2\n",
    "    \n",
    "    # Perform pairwise alignment\n",
    "    alignments = aligner.align(reference_seq, one_letter_seq)\n",
    "    alignment = alignments[0] # We select the first alignment. It could be more than 1 aligment with same score \n",
    "    identity = '{:.2f}'.format(alignment.counts()[1]*100/(len(alignment[0, :])))\n",
    "    gaps = alignment.counts()[0]\n",
    "\n",
    "    # Extract the count of mismatches\n",
    "    mismatches = alignment.counts()[2]\n",
    "    # Where is the mismatch\n",
    "    n = 0\n",
    "    mismatch_location = []\n",
    "\n",
    "    for i, j in zip(alignment[0, :], alignment[1, :]):\n",
    "        if i != '-':\n",
    "            n=n+1\n",
    "            if i!=j and j!='-':\n",
    "                mismatch_location.append(i+str(n)+j)\n",
    "    \n",
    "    return mismatches, mismatch_location, identity, gaps\n",
    "\n",
    "\n",
    "def process_cif_file(file_path, mutation, blacklist, seq_ref, res_threshold):\n",
    "    \"\"\" \n",
    "    Process the cif file analyzing specific data as: ID, chain, number of residues, if it is a complex, \n",
    "    if it is peptide-like complex, the type of the bond and the name of the ligand\n",
    "    \"\"\"\n",
    "\n",
    "    # Función para procesar un archivo CIF y extraer la información requerida\n",
    "    cfr = CifFileReader()\n",
    "    cif_obj = cfr.read(file_path, output='cif_wrapper', ignore=['_atom_site']) # if we are interested in data annotations only and not in coordinates, we can discard the category _atom_site with ignore=['_atom_site'].\n",
    "    cif_data = list(cif_obj.values())[0]\n",
    "\n",
    "    # Variable initialization\n",
    "    ligands=[]\n",
    "    ligand_names=[]\n",
    "    pols=[]\n",
    "    chain=[] # Only of the polymer proteins\n",
    "    num_res=[]  \n",
    "    mismatches_list = []\n",
    "    mismatch_location_list = []\n",
    "    identity_list = [] \n",
    "    gaps_list = []\n",
    "    blacklist_id =[]\n",
    "    peptide_like='No' # if a complex contains one peptide_like ligand, this variable will be 'Yes'\n",
    "    covalent='No' # if one ligand is found to have a covalent bond with the protein, the pdb id is considered covalent='Yes'\n",
    "    covalent_bond=''\n",
    "    bond=''\n",
    "\n",
    "    pdb_id = cif_data['_entry']['id'][0] # The PDB ID\n",
    "    title = cif_data['_struct']['title'][0]\n",
    "\n",
    "    for i in list(zip(cif_data['_entity']['id'],cif_data['_entity']['type'],cif_data['_entity']['src_method'],cif_data['_entity']['pdbx_description'])):\n",
    "        entity_id = i[0]\n",
    "        if i[1] == 'polymer': # if _entity.type is 'polymer' we deduce it is the protein or a peptide ligand  \n",
    "\n",
    "            if i[2] == 'syn': # if _entity.src_method is 'syn', we classify synthetic polymers as peptide ligands\n",
    "                peptide_like='Yes' # Es pot assumir que tots seran peptide-like?\n",
    "                ligand_names.append(i[3])\n",
    "                asym_id=search_asym_id(cif_data,entity_id)\n",
    "                for id_a in asym_id.split(','):\n",
    "                    covalent_bond=check_covalent(cif_data,id_a)\n",
    "                    if covalent_bond:\n",
    "                        covalent='Yes'\n",
    "                        bond=covalent_bond                    \n",
    "\n",
    "                    pep_code=search_peptide_code(cif_data,id_a) # Search if the peptide ligand has a prd.id code, such as 'PRD_000338'\n",
    "                    if pep_code != None:\n",
    "                        if pep_code not in ligands: ligands.append(pep_code)\n",
    "                    else: # Ih the peptide code has not a prd.id code, search the _entity_poly.pdbx_seq_one_letter_code\n",
    "                        seq_one_letter_code=search_peptide_seq_one_letter_code(cif_data,entity_id)\n",
    "                        if seq_one_letter_code != None:\n",
    "                            if seq_one_letter_code not in ligands: ligands.append(seq_one_letter_code)\n",
    "                        else:\n",
    "                            if i[3] not in ligands: ligands.append(i[3])\n",
    "                \n",
    "            else:\n",
    "                if check_polypeptide(cif_data, entity_id) == 'Yes': # Only 'polypeptide(L)' polymers are considered as the main polymers of the structure\n",
    "                    seq = search_peptide_seq_one_letter_code_can(cif_data,entity_id)\n",
    "                      \n",
    "                    # check if its a peptide NEW PART\n",
    "                    if len(seq) < res_threshold:\n",
    "                        peptide_like='Yes' # Es pot assumir que tots seran peptide-like?\n",
    "                        ligand_names.append(i[3])\n",
    "                        asym_id=search_asym_id(cif_data,entity_id)\n",
    "                        for id_a in asym_id.split(','):\n",
    "                            covalent_bond=check_covalent(cif_data,id_a)\n",
    "                            if covalent_bond:\n",
    "                                covalent='Yes'\n",
    "                                bond=covalent_bond \n",
    "                            \n",
    "                            seq_one_letter_code=search_peptide_seq_one_letter_code(cif_data,entity_id)\n",
    "                            if seq_one_letter_code != None:\n",
    "                                if seq_one_letter_code not in ligands: ligands.append(seq_one_letter_code)\n",
    "                            else:\n",
    "                                if i[3] not in ligands: ligands.append(i[3])\n",
    "                                \n",
    "                    else:\n",
    "                        chain.append(search_asym_id(cif_data,entity_id))  # chain is the asym_id of the polymers that are not ligands\n",
    "                        pols.append(i[3])\n",
    "                        num_res.append(str(len(seq)))\n",
    "                        \n",
    "                        mismatches, mismatch_location, identity, gaps = (None, None, None, None)\n",
    "                        if mutation == True:\n",
    "                            mismatches, mismatch_location, identity, gaps = search_for_mutation(seq_ref,seq)  # Ho pot diverses vegades, depen del nombre entity_ids, pero nomes es queda amb el darrer resultat\n",
    "\n",
    "                        #NEW PART\n",
    "                        mismatches_list.append(mismatches)\n",
    "                        mismatch_location_list.append(mismatch_location)\n",
    "                        identity_list.append(identity)\n",
    "                        gaps_list.append(gaps)  \n",
    "\n",
    "        elif i[1] == 'non-polymer': # non-polymer could be ligands or small-molecules from the medium\n",
    "            ligand_code=search_ligand_code(cif_data,entity_id) # From the entity_id, search the ligand_code or sequence (for peptides without a code)\n",
    "            if ligand_code not in blacklist: # Only molecules not present in the blacklist file are considered as ligands\n",
    "                ligands.append(ligand_code)\n",
    "                ligand_names.append(i[3])\n",
    "                asym_id=search_asym_id(cif_data,entity_id)\n",
    "                for id_a in asym_id.split(','):\n",
    "                    covalent_bond=check_covalent(cif_data,id_a)\n",
    "                    if covalent_bond:\n",
    "                        covalent='Yes'\n",
    "                        bond=covalent_bond\n",
    "            if ligand_code in blacklist:\n",
    "                blacklist_id.append(ligand_code)\n",
    "\n",
    "    chain=','.join(chain) # We join all the chains\n",
    "    nchain=chain.count(',')+1\n",
    "    num_res=', '. join(num_res)\n",
    "    ligand_names='\\n'. join(ligand_names)\n",
    "    pols='\\n'.join(pols)\n",
    "    blacklist_id='\\n'. join(blacklist_id)\n",
    "    \n",
    "    if not ligands: complex='No'\n",
    "    else: complex ='Yes'\n",
    "\n",
    "    ligands='\\n'.join(ligands)\n",
    "    if mutation == True:\n",
    "        mismatch_location = ', '.join(mismatch_location)\n",
    "    else:\n",
    "        mismatch_location = None\n",
    "    \n",
    "     # NEW PART\n",
    "    mismatches = '\\n'.join(map(str, mismatches_list))\n",
    "    mismatch_location = '\\n'.join(map(str, mismatch_location_list))\n",
    "    identity = '\\n'.join(map(str,identity_list))\n",
    "    gaps = '\\n'.join(map(str,gaps_list))\n",
    "\n",
    "    return {\n",
    "        \"PDB_ID\": pdb_id,\n",
    "        \"Title\":title,\n",
    "        \"Protein_description\": pols,\n",
    "        \"NChain\":nchain,\n",
    "        \"Chain_ID\": chain,\n",
    "        \"Num_Res\": num_res,\n",
    "        \"Complex\": complex,\n",
    "        \"Descarted_Ligands\": blacklist_id,\n",
    "        \"Ligand\": ligands,\n",
    "        \"Ligand_names\": ligand_names,\n",
    "        \"Peptide_like\": peptide_like,\n",
    "        \"Covalent_Bond\": covalent,\n",
    "        \"Bond\": bond,\n",
    "        \"Mutation\": mismatches,\n",
    "        \"Mutation_Location\": mismatch_location,\n",
    "        \"Identity\": identity,\n",
    "        \"Gaps\": gaps\n",
    "    }\n",
    "\n",
    "\n",
    "def mutation_classification(information_df, output_path):\n",
    "    \"\"\"\n",
    "    Classification based on the information contained in a dataframe. \n",
    "    Downloading PDB files into different folders depend whether there is a mutation.\n",
    "    \"\"\"\n",
    "       \n",
    "    mutated_list = []\n",
    "    no_mutated_list = []\n",
    "\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    with open(information_df, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Mutation'] == '0':\n",
    "                no_mutated_list.append(row['PDB_ID'])\n",
    "            else:\n",
    "                mutated_list.append(row['PDB_ID'])\n",
    "\n",
    "    origin_path = os.getcwd() +'/cif/'\n",
    "\n",
    "    mut_path = output_path + '/Mutated/'\n",
    "    if os.path.exists(mut_path):\n",
    "        mut_path = output_path + '/Mutated_' + current_datetime +'/'\n",
    "        os.makedirs(mut_path)\n",
    "    else: \n",
    "        os.makedirs(mut_path)\n",
    "\n",
    "    non_mut_path = output_path + '/Non-Mutated/'\n",
    "    if os.path.exists(non_mut_path):\n",
    "        non_mut_path = output_path + '/Non-Mutated_' + current_datetime + '/'\n",
    "        os.makedirs(non_mut_path)\n",
    "    else:\n",
    "        os.makedirs(non_mut_path)\n",
    "\n",
    "\n",
    "    for mutated in mutated_list:\n",
    "        pdb_id = mutated.lower()\n",
    "        shutil.copy(origin_path+(pdb_id+\".cif\"), mut_path+(pdb_id+\".cif\"))\n",
    "\n",
    "    for no_mutated in no_mutated_list:\n",
    "        pdb_id = no_mutated.lower()\n",
    "        shutil.copy(origin_path+(pdb_id+\".cif\"), non_mut_path +(pdb_id+\".cif\"))\n",
    "\n",
    "\n",
    "    return no_mutated_list, non_mut_path \n",
    "\n",
    "\n",
    "def bond_classification(information_df, no_mutated_list, output_path, mutation):\n",
    "    \"\"\"\n",
    "    This function classifies between free enzymes and complexes.\n",
    "    And for each complex, it classifies depending on their bonds: covalent or non-covalent.\n",
    "    \"\"\"\n",
    "\n",
    "    free_enzyme_list = []\n",
    "    covalent_list = []\n",
    "    non_covalent_list = []\n",
    "\n",
    "    with open(information_df, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Complex'] == 'No':\n",
    "                if row['PDB_ID'] in no_mutated_list:\n",
    "                    free_enzyme_list.append(row['PDB_ID'])\n",
    "                    \n",
    "            else:\n",
    "                if row['PDB_ID'] in no_mutated_list:\n",
    "                    if row['Covalent_Bond'] == 'Yes':\n",
    "                        covalent_list.append(row['PDB_ID'])\n",
    "                    elif row['Covalent_Bond'] == 'No':\n",
    "                        non_covalent_list.append(row['PDB_ID'])\n",
    "\n",
    "    if mutation == False:\n",
    "        origin_path = os.getcwd() +'/cif/'\n",
    "    elif mutation == True:\n",
    "        origin_path = output_path\n",
    "\n",
    "    free_path = output_path  + 'Free/'\n",
    "    covalent_path = output_path  + 'Covalent/'\n",
    "    non_covalent_path = output_path + 'Non-Covalent/'\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for path in [free_path, covalent_path, non_covalent_path]:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    for free in free_enzyme_list:\n",
    "        pdb_id = free.lower() + \".cif\"\n",
    "        if mutation == True:\n",
    "            shutil.move(origin_path+(pdb_id), free_path+(pdb_id))\n",
    "        if mutation == False:\n",
    "            shutil.copy(origin_path+(pdb_id), free_path+(pdb_id))\n",
    "\n",
    "    for covalent in covalent_list:\n",
    "        pdb_id = covalent.lower() + \".cif\"\n",
    "        if mutation == True:\n",
    "            shutil.move(origin_path+(pdb_id), covalent_path+(pdb_id))\n",
    "        if mutation == False:\n",
    "            shutil.copy(origin_path+(pdb_id), covalent_path+(pdb_id))\n",
    "\n",
    "    for non_covalent in non_covalent_list:\n",
    "        pdb_id = non_covalent.lower() + \".cif\"\n",
    "        if mutation == True:\n",
    "            shutil.move(origin_path+(pdb_id), non_covalent_path+(pdb_id))\n",
    "        if mutation == False:\n",
    "            shutil.copy(origin_path+(pdb_id), non_covalent_path+(pdb_id))\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7TQ5', '7LKE', '5RF1', '7BAK', '5RE4', '6XHU', '5R7Y', '8GXH', '5REB', '5REK', '6YNQ', '5RGI', '7AEG', '7Z4S', '7A1U', '6W63', '7JR4', '7WQ9', '7P51', '6LU7', '7WQ8', '7NIJ', '5RF2', '7ANS', '5REL', '6XB0', '7AQE', '5R8T', '7AP6', '7BAJ', '6XA4', '6M2N', '5REJ', '8GVY', '5RG1', '7RNW', '5R80', '7VVT', '7BAL', '7L14']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=========\n",
    "INITIAL INFORMATION. CHANGE THE CONTENT OF THESE VARIABLES IF NECESSARY\n",
    "\"\"\"\n",
    "information_df ='df.csv' # Path and name of the csv output file\n",
    "mutation = True   # Analyze mutations. True or False\n",
    "output_path = os.getcwd() + '/output/'\n",
    "pdb_reference_sequence = '5r7y.cif' # Path to the pdb file that will be the reference sequence. \n",
    "entity_reference = 0 # '0' means that the first _entity_poly of the pdb_reference_sequence will be the reference sequence\n",
    "reference_seq=''\n",
    "res_threshold = 15 # Chose a threshold to discriminate between peptides and the subunits of the protein\n",
    "\n",
    "\"\"\" \n",
    "MAIN CODE\n",
    "\"\"\"\n",
    "directory_path =os.getcwd()+\"/cif/\"  # Path to the folder with the cif files to process\n",
    "blacklist= read_blacklist(\"./blacklist.txt\") # Path to the blacklist file that contain the codes of the small molecules not considered ligands\n",
    "\n",
    "# READ THE REFERENCE SEQUENCE. It is a PDB file in CIF format.\n",
    "if mutation == True:\n",
    "    ref_cfr = CifFileReader()\n",
    "    ref_cif_obj = ref_cfr.read(pdb_reference_sequence, output='cif_wrapper', ignore=['_atom_site'])\n",
    "    ref_cif_data = list(ref_cif_obj.values())[0]\n",
    "    if '_entity_poly' in ref_cif_data and 'pdbx_seq_one_letter_code_can' in ref_cif_data['_entity_poly']:\n",
    "        reference_seq = ref_cif_data['_entity_poly']['pdbx_seq_one_letter_code_can'][entity_reference]  \n",
    "        reference_seq = reference_seq.replace(\"\\n\", \"\")\n",
    "    \n",
    "data = [] # It will contain the information for each PDB file\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.cif'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        data_from_file = process_cif_file(file_path, mutation, blacklist, reference_seq, res_threshold)\n",
    "        data.append(data_from_file)\n",
    "        \n",
    "df = pd.DataFrame(data) # Create a Pandas df\n",
    "df.to_csv(information_df, index=False) # Save the df into a file\n",
    "        \n",
    "# Classification\n",
    "if mutation == False:\n",
    "    no_mutated_list = [filename[:-4].upper() for filename in os.listdir(directory_path) if filename.endswith('.cif')]\n",
    "\n",
    "if mutation ==True:    \n",
    "    # Classify whether there is a mutation\n",
    "    no_mutated_list, non_mut_path = mutation_classification(information_df, output_path)\n",
    "    print(no_mutated_list)\n",
    "    output_path = non_mut_path \n",
    "\n",
    "# Classify depend on the bond\n",
    "bond_classification(information_df, no_mutated_list, output_path, mutation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
