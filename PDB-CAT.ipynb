{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PDB-CAT**\n",
    "#### **You have the option to explore the code in the following two cells or jump directly into the main code. In the main code section, you should identify and determine the necessary variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PDBCAT_module import *\n",
    "from pdbecif.mmcif_io import CifFileReader\n",
    "from pdbecif.mmcif_tools import MMCIF2Dict\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from Bio.Align import PairwiseAligner \n",
    "from Bio.PDB import *  \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file provided does not exist or is not a file.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mutation \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     ref_cfr \u001b[38;5;241m=\u001b[39m CifFileReader()\n\u001b[0;32m---> 27\u001b[0m     ref_cif_obj \u001b[38;5;241m=\u001b[39m \u001b[43mref_cfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_reference_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcif_wrapper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_atom_site\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     ref_cif_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ref_cif_obj\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_entity_poly\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ref_cif_data:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pdbecif/mmcif_io.py:273\u001b[0m, in \u001b[0;36mCifFileReader.read\u001b[0;34m(self, file_path, output, ignore, preserve_order, only)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mmcif_dict\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcif_wrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    264\u001b[0m         (\n\u001b[1;32m    265\u001b[0m             (\n\u001b[1;32m    266\u001b[0m                 block_id,\n\u001b[1;32m    267\u001b[0m                 CIFWrapper(\n\u001b[1;32m    268\u001b[0m                     block_data,\n\u001b[1;32m    269\u001b[0m                     data_id\u001b[38;5;241m=\u001b[39mblock_id,\n\u001b[1;32m    270\u001b[0m                     preserve_token_order\u001b[38;5;241m=\u001b[39mtoken_ordering,\n\u001b[1;32m    271\u001b[0m                 ),\n\u001b[1;32m    272\u001b[0m             )\n\u001b[0;32m--> 273\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m block_id, block_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mmmcif_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m())\n\u001b[1;32m    274\u001b[0m         )\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# return CIFWrapper(mmcif_dict, data_id=datablock_id)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcif_file\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=========\n",
    "INITIAL INFORMATION. CHANGE THE CONTENT OF THESE VARIABLES IF NECESSARY\n",
    "\"\"\"\n",
    "\n",
    "directory_path =os.getcwd()+\"/cif_prova\"  # Path to the folder with the cif files to process\n",
    "out_file='df_2002.csv'\n",
    "out_file_ligands= 'df_2002_ligands.csv' # Path and name of the csv output file\n",
    "mutation = False      # Analyze mutations. True or False\n",
    "output_path = './OUT/'\n",
    "pdb_reference_sequence = '' # Path to the pdb file that will be the reference sequence. \n",
    "entity_reference = 0 # '0' means that the first _entity_poly of the pdb_reference_sequence will be the reference sequence\n",
    "res_threshold = 20 # Chose a threshold to discriminate between peptides and the subunits of the protein\n",
    "blacklist, blacklist_dict = read_blacklist(\"./blacklist.txt\") # Path to the blacklist file that contain the codes of the small molecules not considered ligands\n",
    "\n",
    "\"\"\" \n",
    "MAIN CODE\n",
    "\"\"\"\n",
    "\n",
    "# READ THE REFERENCE SEQUENCE. It is a PDB file in CIF format.\n",
    "reference_seq=''\n",
    "if mutation == True:\n",
    "    ref_cfr = CifFileReader()\n",
    "    ref_cif_obj = ref_cfr.read(pdb_reference_sequence, output='cif_wrapper', ignore=['_atom_site'])\n",
    "    ref_cif_data = list(ref_cif_obj.values())[0]\n",
    "    if '_entity_poly' in ref_cif_data:\n",
    "        reference_seq = ref_cif_data['_entity_poly']['pdbx_seq_one_letter_code_can'][entity_reference]  \n",
    "        reference_seq = reference_seq.replace(\"\\n\",\"\")\n",
    "\n",
    "# First csv output. Protein-centered\n",
    "# Second csv output. Ligand-centered\n",
    "        \n",
    "data = [] # It will contain the information for each PDB file\n",
    "data_ligands = []  # It will contain the information for each PDB file\n",
    "fields_to_include = [\"PDB_ID\", \"Ligand\", \"Ligand_names\",\"Ligand_types\", \"Ligand_functions\", \"Covalent_Bond\", \"Bond\"]\n",
    "fields_to_append = [\"PDB_ID\"]\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.cif'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        data_from_file = process_cif_file(file_path, mutation, blacklist, reference_seq, res_threshold)\n",
    "        data.append(data_from_file)\n",
    "\n",
    "        # Split ligand names and create a new row for each ligand\n",
    "        ligands = data_from_file[\"Ligand\"].split('\\n')\n",
    "        ligand_names_list = data_from_file[\"Ligand_names\"].split('\\n')\n",
    "        ligand_types_list = data_from_file[\"Ligand_types\"].split('\\n')\n",
    "        covalent_bond_list = data_from_file[\"Covalent_Bond\"].split('\\n')\n",
    "        ligand_covalents_bond = data_from_file[\"Bond\"].split('\\n')\n",
    "        descarted_ligands = data_from_file[\"Descarted_Ligands\"].split('\\n')\n",
    "        branched_molecules = data_from_file[\"Branched\"].split('\\n')\n",
    "        branched_name = data_from_file[\"Branched_name\"].split('\\n')\n",
    "        branched_type = data_from_file[\"Branched_type\"].split('\\n')\n",
    "        branched_covalent = data_from_file[\"Branched_Covalent\"].split('\\n')\n",
    "        branched_bond = data_from_file[\"Branched_Bond\"].split('\\n')\n",
    "\n",
    "\n",
    "        # Find the maximum length among the three lists\n",
    "        max_length = max(len(ligands), len(ligand_names_list), len(ligand_types_list), len(covalent_bond_list), len(ligand_covalents_bond), len(descarted_ligands), len(branched_molecules))\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            ligand_row = {field: data_from_file[field] for field in fields_to_include}\n",
    "\n",
    "            # Get the element from each list\n",
    "            ligand_row[\"Ligand\"]= ligands[i].strip() if i < len(ligands) else \"\"\n",
    "            ligand_row[\"Ligand_names\"] = ligand_names_list[i].strip() if i < len(ligand_names_list) else \"\"\n",
    "            ligand_row[\"Ligand_types\"] = ligand_types_list[i].strip() if i < len(ligand_types_list) else \"\"\n",
    "            ligand_row[\"Covalent_Bond\"] = covalent_bond_list[i].strip() if i < len(covalent_bond_list) else \"\"\n",
    "            ligand_row[\"Bond\"] = ligand_covalents_bond[i].strip() if i < len(ligand_covalents_bond) else \"\"\n",
    "            data_ligands.append(ligand_row)\n",
    "         \n",
    "\n",
    "            # Añadir columna al DataFrame de ligandos y rellenar con información correspondiente\n",
    "            if i < len(descarted_ligands) and descarted_ligands[i].strip():  # Asegurar que hay información antes de agregar\n",
    "                ligand_row_discarded = {field: data_from_file[field] for field in fields_to_include}\n",
    "                ligand_row_discarded[\"Ligand\"] = descarted_ligands[i].strip()\n",
    "                ligand_row_discarded[\"Ligand_names\"] = blacklist_dict[descarted_ligands[i].strip()]\n",
    "                ligand_row_discarded[\"Ligand_types\"] = \"Discarded\"\n",
    "                ligand_row_discarded[\"Covalent_Bond\"] = \"\"\n",
    "                ligand_row_discarded[\"Bond\"] = \"\"\n",
    "                data_ligands.append(ligand_row_discarded)\n",
    "            \n",
    "            # Añadir columna al DataFrame de ligandos y rellenar con información correspondiente\n",
    "            if i < len(branched_molecules) and branched_molecules[i].strip():  # Asegurar que hay información antes de agregar\n",
    "                ligand_row_branched = {field: data_from_file[field] for field in fields_to_include}\n",
    "                ligand_row_branched[\"Ligand\"] = branched_molecules[i].strip() if i < len(branched_molecules) else \"\"\n",
    "                ligand_row_branched[\"Ligand_names\"] = branched_name[i].strip() if i < len(branched_name) else \"\"\n",
    "                ligand_row_branched[\"Ligand_types\"] = \"Branched\"\n",
    "                ligand_row_branched[\"Covalent_Bond\"] = branched_covalent[i].strip() if i < len(branched_covalent) else \"\"\n",
    "                ligand_row_branched[\"Bond\"] = branched_bond[i].strip() if i < len(branched_bond) else \"\"\n",
    "                data_ligands.append(ligand_row_branched)\n",
    "\n",
    "# First csv output. Protein-centered\n",
    "df = pd.DataFrame(data)  # Create a Pandas df\n",
    "df.to_csv(out_file, index=False)  # Save the df into a file\n",
    "\n",
    "# Second csv output. Ligand-centered\n",
    "df_ligand = pd.DataFrame(data_ligands) # Create a Pandas df\n",
    "\n",
    "# Eliminar filas donde 'Ligand' está vacío o solo contiene espacios en blanco\n",
    "df_ligand['Ligand'] = df_ligand['Ligand'].str.strip()  # Eliminar espacios en blanco alrededor\n",
    "df_ligand = df_ligand[df_ligand['Ligand'] != '']  # Eliminar filas donde 'Ligand' está vacío \n",
    "\n",
    "# Definir los nuevos nombres de las columnas\n",
    "new_header = ['ID', 'Molecule', 'Name', 'Type', 'Function', 'Covalent', 'Bond']\n",
    "df_ligand.columns = new_header\n",
    "\n",
    "df_ligand.to_csv(out_file_ligands, index=False) # Save the df into a file\n",
    "\n",
    "# Classification\n",
    "if mutation == False:\n",
    "    no_mutated_list = os.listdir(directory_path)\n",
    "    no_mutated_list = [filename[:-4].upper() for filename in no_mutated_list]\n",
    "\n",
    "if mutation ==True:    \n",
    "    # Classify whether there is a mutation\n",
    "    no_mutated_list, non_mut_path = mutation_classification(\"df.csv\", output_path)\n",
    "    output_path = non_mut_path \n",
    "\n",
    "# Classify depend on the bond\n",
    "#bond_classification(out_file, no_mutated_list, output_path, mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
