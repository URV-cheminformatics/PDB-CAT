{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PDB-CAT**\n",
    "#### **You have the option to explore the code in the following two cells or jump directly into the main code. In the main code section, you should identify and determine the necessary variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PDBCAT_module import *\n",
    "from pdbecif.mmcif_io import CifFileReader\n",
    "from pdbecif.mmcif_tools import MMCIF2Dict\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from Bio.Align import PairwiseAligner \n",
    "from Bio.PDB import *  \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ariadna/PDB-CAT_repository/cif_prova'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m fields_to_include \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDB_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLigand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLigand_names\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLigand_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLigand_functions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCovalent_Bond\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBond\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     36\u001b[0m fields_to_append \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDB_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.cif\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     40\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory_path, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ariadna/PDB-CAT_repository/cif_prova'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=========\n",
    "INITIAL INFORMATION. CHANGE THE CONTENT OF THESE VARIABLES IF NECESSARY\n",
    "\"\"\"\n",
    "\n",
    "directory_path = \"\"                         # Path to the folder with the cif files to process\n",
    "out_file = \"\"                                 # Path and name of the FIRST csv output file (protein-centered) (.csv)\n",
    "out_file_ligands = \"\"                        # Path and name of the SECOND csv output file (ligand-centered) (.csv)\n",
    "mutation = True                             # Analyze mutations. True or False\n",
    "output_path = \"\"                            # Path for the new categorizing folders\n",
    "pdb_reference_sequence = \"\"                 # Path to the pdb file that will be the reference sequence. \n",
    "entity_reference = 0                        # '0' means that the first _entity_poly of the pdb_reference_sequence will be the reference sequence\n",
    "res_threshold = 15                          # Chose a threshold to discriminate between peptides and the subunits of the protein\n",
    "\n",
    "\"\"\"\n",
    "====================================================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" \n",
    "MAIN CODE. YOU DO NOT NEED TO CHANGE THIS PART\n",
    "\"\"\"\n",
    "\n",
    "blacklist, blacklist_dict = read_blacklist(\"./blacklist.txt\") # Path to the blacklist file that contain the codes of the small molecules not considered ligands\n",
    "\n",
    "# READ THE REFERENCE SEQUENCE. It is a PDB file in CIF format.\n",
    "reference_seq=''\n",
    "if mutation == True:\n",
    "    ref_cfr = CifFileReader()\n",
    "    ref_cif_obj = ref_cfr.read(pdb_reference_sequence, output='cif_wrapper', ignore=['_atom_site'])\n",
    "    ref_cif_data = list(ref_cif_obj.values())[0]\n",
    "    if '_entity_poly' in ref_cif_data:\n",
    "        reference_seq = ref_cif_data['_entity_poly']['pdbx_seq_one_letter_code_can'][entity_reference]  \n",
    "        reference_seq = reference_seq.replace(\"\\n\",\"\")\n",
    "\n",
    "# First csv output. Protein-centered\n",
    "# Second csv output. Ligand-centered\n",
    "        \n",
    "data = []          \n",
    "data_ligands = []   \n",
    "fields_to_include = [\"PDB_ID\", \"Ligand\", \"Ligand_names\",\"Ligand_types\", \"Ligand_functions\", \"Covalent_Bond\", \"Bond\"]\n",
    "fields_to_append = [\"PDB_ID\"]\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.cif'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        data_from_file = process_cif_file(file_path, mutation, blacklist, reference_seq, res_threshold)\n",
    "        data.append(data_from_file)\n",
    "\n",
    "        # Split ligand names and create a new row for each ligand\n",
    "        ligands = data_from_file[\"Ligand\"].split('\\n')\n",
    "        ligand_names_list = data_from_file[\"Ligand_names\"].split('\\n')\n",
    "        ligand_types_list = data_from_file[\"Ligand_types\"].split('\\n')\n",
    "        covalent_bond_list = data_from_file[\"Covalent_Bond\"].split('\\n')\n",
    "        ligand_covalents_bond = data_from_file[\"Bond\"].split('\\n')\n",
    "        descarted_ligands = data_from_file[\"Discarted_Ligands\"].split('\\n')\n",
    "        branched_molecules = data_from_file[\"Branched\"].split('\\n')\n",
    "        branched_name = data_from_file[\"Branched_name\"].split('\\n')\n",
    "        branched_type = data_from_file[\"Branched_type\"].split('\\n')\n",
    "        branched_covalent = data_from_file[\"Branched_Covalent\"].split('\\n')\n",
    "        branched_bond = data_from_file[\"Branched_Bond\"].split('\\n')\n",
    "\n",
    "\n",
    "        # Find the maximum length among the three lists\n",
    "        max_length = max(len(ligands), len(ligand_names_list), len(ligand_types_list), len(covalent_bond_list), len(ligand_covalents_bond), len(descarted_ligands), len(branched_molecules))\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            ligand_row = {field: data_from_file[field] for field in fields_to_include}\n",
    "\n",
    "            # Get the element from each list\n",
    "            ligand_row[\"Ligand\"]= ligands[i].strip() if i < len(ligands) else \"\"\n",
    "            ligand_row[\"Ligand_names\"] = ligand_names_list[i].strip() if i < len(ligand_names_list) else \"\"\n",
    "            ligand_row[\"Ligand_types\"] = ligand_types_list[i].strip() if i < len(ligand_types_list) else \"\"\n",
    "            ligand_row[\"Covalent_Bond\"] = covalent_bond_list[i].strip() if i < len(covalent_bond_list) else \"\"\n",
    "            ligand_row[\"Bond\"] = ligand_covalents_bond[i].strip() if i < len(ligand_covalents_bond) else \"\"\n",
    "            data_ligands.append(ligand_row)\n",
    "         \n",
    "\n",
    "            # Add column to the ligands DataFrame and fill it with corresponding information\n",
    "            if i < len(descarted_ligands) and descarted_ligands[i].strip():  # Ensure there is information before adding\n",
    "                ligand_row_discarded = {field: data_from_file[field] for field in fields_to_include}\n",
    "                ligand_row_discarded[\"Ligand\"] = descarted_ligands[i].strip()\n",
    "                ligand_row_discarded[\"Ligand_names\"] = blacklist_dict[descarted_ligands[i].strip()]\n",
    "                ligand_row_discarded[\"Ligand_types\"] = \"Discarded\"\n",
    "                ligand_row_discarded[\"Covalent_Bond\"] = \"\"\n",
    "                ligand_row_discarded[\"Bond\"] = \"\"\n",
    "                data_ligands.append(ligand_row_discarded)\n",
    "            \n",
    "            # Add a column to the ligands DataFrame and fill it with the corresponding information\n",
    "            if i < len(branched_molecules) and branched_molecules[i].strip():  \n",
    "                ligand_row_branched = {field: data_from_file[field] for field in fields_to_include}\n",
    "                ligand_row_branched[\"Ligand\"] = branched_molecules[i].strip() if i < len(branched_molecules) else \"\"\n",
    "                ligand_row_branched[\"Ligand_names\"] = branched_name[i].strip() if i < len(branched_name) else \"\"\n",
    "                ligand_row_branched[\"Ligand_types\"] = \"Branched\"\n",
    "                ligand_row_branched[\"Covalent_Bond\"] = branched_covalent[i].strip() if i < len(branched_covalent) else \"\"\n",
    "                ligand_row_branched[\"Bond\"] = branched_bond[i].strip() if i < len(branched_bond) else \"\"\n",
    "                data_ligands.append(ligand_row_branched)\n",
    "\n",
    "# First csv output. Protein-centered\n",
    "df = pd.DataFrame(data)  # Create a Pandas df\n",
    "df.to_csv(out_file, index=False)  # Save the df into a file\n",
    "\n",
    "# Second csv output. Ligand-centered\n",
    "df_ligand = pd.DataFrame(data_ligands) # Create a Pandas df\n",
    "\n",
    "# Remove rows where 'Ligand' is empty or contains only white spaces\n",
    "df_ligand['Ligand'] = df_ligand['Ligand'].str.strip()  \n",
    "df_ligand = df_ligand[df_ligand['Ligand'] != '']  \n",
    "\n",
    "# Define the new names for the columns\n",
    "new_header = ['ID', 'Molecule', 'Name', 'Type', 'Function', 'Covalent', 'Bond']\n",
    "df_ligand.columns = new_header\n",
    "\n",
    "# Second csv output. Ligand-centered\n",
    "df_ligand.to_csv(out_file_ligands, index=False) # Save the df into a file\n",
    "\n",
    "# Classify whether there is a mutation\n",
    "if mutation == False:\n",
    "    no_mutated_list = os.listdir(directory_path)\n",
    "    no_mutated_list = [filename[:-4].upper() for filename in no_mutated_list]\n",
    "\n",
    "if mutation ==True:    \n",
    "    no_mutated_list, non_mut_path = mutation_classification(directory_path, out_file, output_path)\n",
    "    output_path = non_mut_path \n",
    "\n",
    "# Classify depend on the bond\n",
    "bond_classification(directory_path, out_file, no_mutated_list, output_path, mutation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
