{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PDB-CAT**\n",
    "#### **You have the option to explore the code in the following two cells or jump directly into the main code. In the main code section, you should identify and determine the necessary variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "# !pip install --quiet rdkit\n",
    "# !pip install --quiet pdbecif\n",
    "# !pip install --quiet biopython\n",
    "# !pip install --quiet time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PDBCAT_module import *\n",
    "from pdbecif.mmcif_io import CifFileReader\n",
    "from pdbecif.mmcif_tools import MMCIF2Dict\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from Bio.Align import PairwiseAligner \n",
    "from Bio.PDB import *  \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB-CAT installed\n"
     ]
    }
   ],
   "source": [
    "# Check if the PDB-CAT repository has been cloned and installed\n",
    "if not os.path.isfile(\"PDB-CAT_READY\"):\n",
    "    os.system(\"git clone https://github.com/URV-cheminformatics/PDB-CAT.git\")\n",
    "    os.chdir(\"PDB-CAT\")  # Change directory to the cloned repository\n",
    "    os.system(\"pip install -r requirements.txt\")  # Install PDB-CAT if it has a setup.py or pyproject.toml\n",
    "    os.chdir(\"..\")  # Change back to the original directory\n",
    "    os.system(\"touch PDB-CAT_READY\")  # Create the PDB-CAT_READY file to indicate successful cloning and installation\n",
    "print(\"PDB-CAT installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/cif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Check if the 'cif' directory exists, if not, create it\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cif_dir):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcif_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the 'out' directory exists, if not, create it\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(out_dir):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/cif'"
     ]
    }
   ],
   "source": [
    "# Check if you have the correct folders\n",
    "os.chdir(\"PDB-CAT\")\n",
    "cif_dir = os.path.join(os.getcwd(), \"/cif\")\n",
    "out_dir = os.path.join(os.getcwd(), \"/out\")\n",
    "\n",
    "# Check if the 'cif' directory exists, if not, create it\n",
    "if not os.path.exists(cif_dir):\n",
    "    os.mkdir(cif_dir)\n",
    "\n",
    "# Check if the 'out' directory exists, if not, create it\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========\n",
    "INITIAL INFORMATION. CHANGE THE CONTENT OF THESE VARIABLES IF NECESSARY\n",
    "\"\"\"\n",
    "\n",
    "directory_path = os.getcwd()+\"/cif/\"        # Path to the folder with the cif files to process\n",
    "out_file = \"df.csv\"                         # Path and name of the FIRST csv output file (protein-centered) (.csv)\n",
    "out_file_ligands = \"df_ligands.csv\"         # Path and name of the SECOND csv output file (ligand-centered) (.csv)\n",
    "mutation = False                           # Analyze mutations. True or False\n",
    "output_path = \"./out/\"                      # Path for the new categorizing folders\n",
    "pdb_reference_sequence = \"\"                 # Path to the pdb file that will be the reference sequence. \n",
    "entity_reference = 0                        # '0' means that the first _entity_poly of the pdb_reference_sequence will be the reference sequence\n",
    "res_threshold = 15                          # Chose a threshold to discriminate between peptides and the subunits of the protein\n",
    "\n",
    "\"\"\"\n",
    "====================================================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" \n",
    "MAIN CODE. YOU DO NOT NEED TO CHANGE THIS PART\n",
    "\"\"\"\n",
    "\n",
    "blacklist, blacklist_dict = read_blacklist(\"./blacklist.txt\") # Path to the blacklist file that contain the codes of the small molecules not considered ligands\n",
    "\n",
    "# READ THE REFERENCE SEQUENCE. It is a PDB file in CIF format.\n",
    "reference_seq=''\n",
    "if mutation == True:\n",
    "    ref_cfr = CifFileReader()\n",
    "    ref_cif_obj = ref_cfr.read(pdb_reference_sequence, output='cif_wrapper', ignore=['_atom_site'])\n",
    "    ref_cif_data = list(ref_cif_obj.values())[0]\n",
    "    if '_entity_poly' in ref_cif_data:\n",
    "        reference_seq = ref_cif_data['_entity_poly']['pdbx_seq_one_letter_code_can'][entity_reference]  \n",
    "        reference_seq = reference_seq.replace(\"\\n\",\"\")\n",
    "\n",
    "# First csv output. Protein-centered\n",
    "# Second csv output. Ligand-centered\n",
    "        \n",
    "data = []          \n",
    "data_ligands = []   \n",
    "fields_to_include = [\"PDB_ID\", \"Ligand\", \"Ligand_names\",\"Ligand_types\", \"Ligand_functions\", \"Covalent_Bond\", \"Bond\"]\n",
    "fields_to_append = [\"PDB_ID\"]\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.cif'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        data_from_file = process_cif_file(file_path, mutation, blacklist, reference_seq, res_threshold)\n",
    "        data.append(data_from_file)\n",
    "\n",
    "        # Split ligand names and create a new row for each ligand\n",
    "        ligands = data_from_file[\"Ligand\"].split('\\n')\n",
    "        ligand_names_list = data_from_file[\"Ligand_names\"].split('\\n')\n",
    "        ligand_types_list = data_from_file[\"Ligand_types\"].split('\\n')\n",
    "        covalent_bond_list = data_from_file[\"Covalent_Bond\"].split('\\n')\n",
    "        ligand_covalents_bond = data_from_file[\"Bond\"].split('\\n')\n",
    "        descarted_ligands = data_from_file[\"Discarted_Ligands\"].split('\\n')\n",
    "        branched_molecules = data_from_file[\"Branched\"].split('\\n')\n",
    "        branched_name = data_from_file[\"Branched_name\"].split('\\n')\n",
    "        branched_type = data_from_file[\"Branched_type\"].split('\\n')\n",
    "        branched_covalent = data_from_file[\"Branched_Covalent\"].split('\\n')\n",
    "        branched_bond = data_from_file[\"Branched_Bond\"].split('\\n')\n",
    "\n",
    "\n",
    "        # Find the maximum length among the three lists\n",
    "        max_length = max(len(ligands), len(ligand_names_list), len(ligand_types_list), len(covalent_bond_list), len(ligand_covalents_bond), len(descarted_ligands), len(branched_molecules))\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            ligand_row = {field: data_from_file[field] for field in fields_to_include}\n",
    "\n",
    "            # Get the element from each list\n",
    "            ligand_row[\"Ligand\"]= ligands[i].strip() if i < len(ligands) else \"\"\n",
    "            ligand_row[\"Ligand_names\"] = ligand_names_list[i].strip() if i < len(ligand_names_list) else \"\"\n",
    "            ligand_row[\"Ligand_types\"] = ligand_types_list[i].strip() if i < len(ligand_types_list) else \"\"\n",
    "            ligand_row[\"Covalent_Bond\"] = covalent_bond_list[i].strip() if i < len(covalent_bond_list) else \"\"\n",
    "            ligand_row[\"Bond\"] = ligand_covalents_bond[i].strip() if i < len(ligand_covalents_bond) else \"\"\n",
    "            data_ligands.append(ligand_row)\n",
    "         \n",
    "\n",
    "            # Add column to the ligands DataFrame and fill it with corresponding information\n",
    "            if i < len(descarted_ligands) and descarted_ligands[i].strip():  # Ensure there is information before adding\n",
    "                ligand_row_discarded = {field: data_from_file[field] for field in fields_to_include}\n",
    "                ligand_row_discarded[\"Ligand\"] = descarted_ligands[i].strip()\n",
    "                ligand_row_discarded[\"Ligand_names\"] = blacklist_dict[descarted_ligands[i].strip()]\n",
    "                ligand_row_discarded[\"Ligand_types\"] = \"Discarded\"\n",
    "                ligand_row_discarded[\"Covalent_Bond\"] = \"\"\n",
    "                ligand_row_discarded[\"Bond\"] = \"\"\n",
    "                data_ligands.append(ligand_row_discarded)\n",
    "            \n",
    "            # Add a column to the ligands DataFrame and fill it with the corresponding information\n",
    "            if i < len(branched_molecules) and branched_molecules[i].strip():  \n",
    "                ligand_row_branched = {field: data_from_file[field] for field in fields_to_include}\n",
    "                ligand_row_branched[\"Ligand\"] = branched_molecules[i].strip() if i < len(branched_molecules) else \"\"\n",
    "                ligand_row_branched[\"Ligand_names\"] = branched_name[i].strip() if i < len(branched_name) else \"\"\n",
    "                ligand_row_branched[\"Ligand_types\"] = \"Branched\"\n",
    "                ligand_row_branched[\"Covalent_Bond\"] = branched_covalent[i].strip() if i < len(branched_covalent) else \"\"\n",
    "                ligand_row_branched[\"Bond\"] = branched_bond[i].strip() if i < len(branched_bond) else \"\"\n",
    "                data_ligands.append(ligand_row_branched)\n",
    "\n",
    "# First csv output. Protein-centered\n",
    "df = pd.DataFrame(data)  # Create a Pandas df\n",
    "df.to_csv(out_file, index=False)  # Save the df into a file\n",
    "\n",
    "# Second csv output. Ligand-centered\n",
    "df_ligand = pd.DataFrame(data_ligands) # Create a Pandas df\n",
    "\n",
    "# Remove rows where 'Ligand' is empty or contains only white spaces\n",
    "df_ligand['Ligand'] = df_ligand['Ligand'].str.strip()  \n",
    "df_ligand = df_ligand[df_ligand['Ligand'] != '']  \n",
    "\n",
    "# Define the new names for the columns\n",
    "new_header = ['ID', 'Molecule', 'Name', 'Type', 'Function', 'Covalent', 'Bond']\n",
    "df_ligand.columns = new_header\n",
    "\n",
    "# Second csv output. Ligand-centered\n",
    "df_ligand.to_csv(out_file_ligands, index=False) # Save the df into a file\n",
    "\n",
    "# Classify whether there is a mutation\n",
    "if mutation == False:\n",
    "    no_mutated_list = os.listdir(directory_path)\n",
    "    no_mutated_list = [filename[:-4] for filename in no_mutated_list]\n",
    "\n",
    "if mutation ==True:    \n",
    "    no_mutated_list, non_mut_path = mutation_classification(directory_path, out_file, output_path)\n",
    "    output_path = non_mut_path \n",
    "\n",
    "# Classify depend on the bond\n",
    "bond_classification(directory_path, out_file, no_mutated_list, output_path, mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Package and Download results { display-mode: \"form\" }\n",
    "results_zip = f\"3CL-proteinase_result.zip\"\n",
    "os.system(f\"zip -r {results_zip} {output_path} {github}/protein_features/3CL-proteinase.pkl.bz2\")\n",
    "files.download(results_zip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
