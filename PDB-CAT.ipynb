{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDB-CAT Cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdbecif.mmcif_io import CifFileReader\n",
    "from pdbecif.mmcif_tools import MMCIF2Dict\n",
    "import pandas as pd\n",
    "#from tqdm.notebook import tqdm\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from Bio.Align import PairwiseAligner  # for pairwise sequence alignment\n",
    "from Bio.PDB import *  # for working with PDB files\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_blacklist(blacklist_path):\n",
    "\n",
    "    with open(blacklist_path, 'r') as f:\n",
    "        linea = f.read()\n",
    "    linea=linea.replace(' ','')\n",
    "    blacklist = linea.strip('\\n').split(',')\n",
    "\n",
    "    return blacklist\n",
    "\n",
    "def search_asym_id(cif_data,entity_id):\n",
    "    # From _entity_id we search the _struct_asym.id\n",
    "    # The _struct_asym.id is also the chain or subunit\n",
    "    asym_id=[]\n",
    "    if '_struct_asym' in cif_data:\n",
    "        for r in cif_data._struct_asym.search('entity_id',entity_id).values():\n",
    "            asym_id.append(r['id'])\n",
    "        asym_id=','.join(asym_id)\n",
    "\n",
    "    return asym_id\n",
    "\n",
    "def search_peptide_code(cif_data,asym_id):\n",
    "    # Data items in the PDBX_MOLECULE category identify reference molecules within a PDB entry.\n",
    "    # The value of _pdbx_molecule.prd_id is the PDB accession code for this reference molecule.\n",
    "    pep_code=''\n",
    "    if '_pdbx_molecule' in cif_data:\n",
    "        for r in cif_data._pdbx_molecule.search('asym_id',asym_id).values():\n",
    "            pep_code=r['prd_id']\n",
    "        return pep_code\n",
    "\n",
    "def search_ligand_code(cif_data, entity_id):\n",
    "    # From the entity_id we search _pdbx_entity_nonpoly.comp_id which is a pointer to the _chem_comp.id\n",
    "    comp_id=''\n",
    "    if '_pdbx_entity_nonpoly' in cif_data:\n",
    "        for r in cif_data._pdbx_entity_nonpoly.search('entity_id',entity_id).values():\n",
    "            comp_id=r['comp_id']\n",
    "        return comp_id\n",
    "    \n",
    "def check_polypeptide(cif_data, entity_id):\n",
    "    # Check if the polymer is a 'polypeptide(L)'. Only polypeptides are considered as the main polymers\n",
    "    # Data items in the ENTITY_POLY category record details about the polymer, such as the type of the polymer, the number of monomers and whether it has nonstandard features.\n",
    "    # _entity_poly.type contains the type of the polymer. It can be: cyclic-pseudo-peptide, other, peptide nucleic acid, polydeoxyribonucleotide, polydeoxyribonucleotide/polyribonucleotide hybrid, polypeptide(D), polypeptide(L), polyribonucleotide, polysaccharide(D), polysaccharide(L)\n",
    "    if '_entity_poly' in cif_data:\n",
    "        for r in cif_data._entity_poly.search('entity_id',entity_id).values():\n",
    "            if r['type'] == 'polypeptide(L)':\n",
    "                return 'Yes'\n",
    "            else:\n",
    "                return 'No'\n",
    "            \n",
    "def check_covalent(cif_data,asym_id): # Check if the ligand has a covalent bond with the protein\n",
    "    if '_struct_conn' in cif_data:\n",
    "        for r in cif_data._struct_conn.search('conn_type_id','covale').values(): \n",
    "            if r['ptnr2_label_asym_id'] == asym_id and r['ptnr2_label_asym_id'] != r['ptnr1_label_asym_id']: # Millorar i comprovar que l'altre asym_id es de la proteina\n",
    "                return r['ptnr1_label_comp_id']+r['ptnr1_auth_seq_id'] # abans ptnr1_label_seq_id\n",
    "            if r['ptnr1_label_asym_id'] == asym_id and r['ptnr2_label_asym_id'] != r['ptnr1_label_asym_id']:\n",
    "                return r['ptnr2_label_comp_id']+r['ptnr2_auth_seq_id'] # abans ptnr2_label_seq_id\n",
    "\n",
    "def search_peptide_seq_one_letter_code(cif_data,entity_id):\n",
    "    if '_entity_poly' in cif_data:\n",
    "        for r in cif_data._entity_poly.search('entity_id',entity_id).values():\n",
    "            seq_one_letter_code = r['pdbx_seq_one_letter_code']\n",
    "            \n",
    "        return seq_one_letter_code\n",
    "    \n",
    "def search_peptide_seq_one_letter_code_can(cif_data,entity_id):\n",
    "    if '_entity_poly' in cif_data:\n",
    "        for r in cif_data._entity_poly.search('entity_id',entity_id).values():\n",
    "            seq_one_letter_code_can = ''.join(r['pdbx_seq_one_letter_code_can'].splitlines())\n",
    "            \n",
    "        return seq_one_letter_code_can\n",
    "\n",
    "def search_for_mutation(reference_seq, one_letter_seq):\n",
    "    \"\"\" \n",
    "    Search for mutations, where is the mismatch, how many gaps there are and the identity of the sequence\n",
    "    \"\"\"\n",
    "\n",
    "    # Define aligner variables from PairwiseAligner\n",
    "    aligner = PairwiseAligner()\n",
    "    aligner.mode = 'global'\n",
    "    aligner.match_score = 5\n",
    "    aligner.mismatch_score = -3\n",
    "    aligner.open_gap_score = -7\n",
    "    aligner.extend_gap_score = -2\n",
    "    \n",
    "    # Perform pairwise alignment\n",
    "    alignments = aligner.align(reference_seq, one_letter_seq)\n",
    "    \n",
    "    alignment = alignments[0] # We select the first alignment. It could be more than 1 aligment with same score\n",
    "\n",
    "    #print(alignment)\n",
    "    #print(alignment.counts())\n",
    " \n",
    "    identity = '{:.2f}'.format(alignment.counts()[1]*100/(len(alignment[0, :])))\n",
    "    gaps = alignment.counts()[0]\n",
    "\n",
    "    # Extract the count of mismatches\n",
    "    mismatches = alignment.counts()[2]\n",
    "    # Where is the mismatch\n",
    "    n = 0\n",
    "    mismatch_location = []\n",
    "\n",
    "    for i, j in zip(alignment[0, :], alignment[1, :]):\n",
    "        if i != '-':\n",
    "            n=n+1\n",
    "            if i!=j and j!='-':\n",
    "                mismatch_location.append(i+str(n)+j)\n",
    "    \n",
    "    return mismatches, mismatch_location, identity, gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cif_file(file_path, mutation, blacklist, seq_ref):\n",
    "    \"\"\" \n",
    "    Process the cif file analyzing specific data as: ID, chain, number of residues, if it is a complex, \n",
    "    if it is peptide-like complex, the type of the bond and the name of the ligand\n",
    "    \"\"\"\n",
    "\n",
    "    # Función para procesar un archivo CIF y extraer la información requerida\n",
    "    cfr = CifFileReader()\n",
    "    cif_obj = cfr.read(file_path, output='cif_wrapper', ignore=['_atom_site']) # if we are interested in data annotations only and not in coordinates, we can discard the category _atom_site with ignore=['_atom_site'].\n",
    "    cif_data = list(cif_obj.values())[0]\n",
    "\n",
    "    # Variable initialization\n",
    "    ligands=[]\n",
    "    ligand_names=[]\n",
    "    pols=[]\n",
    "    chain=[] # Only of the polymer proteins\n",
    "    num_res=[]\n",
    "    peptide_like='No' # if a complex contains one peptide_like ligand, this variable will be 'Yes'\n",
    "    covalent='No' # if one ligand is found to have a covalent bond with the protein, the pdb id is considered covalent='Yes'\n",
    "    covalent_bond=''\n",
    "    bond=''\n",
    "\n",
    "    pdb_id = cif_data['_entry']['id'][0] # The PDB ID\n",
    "    title = cif_data['_struct']['title'][0]\n",
    "\n",
    "    for i in list(zip(cif_data['_entity']['id'],cif_data['_entity']['type'],cif_data['_entity']['src_method'],cif_data['_entity']['pdbx_description'])):\n",
    "        entity_id = i[0]\n",
    "        if i[1] == 'polymer': # if _entity.type is 'polymer' we deduce it is the protein or a peptide ligand  \n",
    "\n",
    "            if i[2] == 'syn': # if _entity.src_method is 'syn', we classify synthetic polymers as peptide ligands\n",
    "                peptide_like='Yes' # Es pot assumir que tots seran peptide-like?\n",
    "                ligand_names.append(i[3])\n",
    "                asym_id=search_asym_id(cif_data,entity_id)\n",
    "                for id_a in asym_id.split(','):\n",
    "                    covalent_bond=check_covalent(cif_data,id_a)\n",
    "                    if covalent_bond:\n",
    "                        covalent='Yes'\n",
    "                        bond=covalent_bond                    \n",
    "\n",
    "                    pep_code=search_peptide_code(cif_data,id_a) # Search if the peptide ligand has a prd.id code, such as 'PRD_000338'\n",
    "                    if pep_code != None:\n",
    "                        if pep_code not in ligands: ligands.append(pep_code)\n",
    "                    else: # Ih the peptide code has not a prd.id code, search the _entity_poly.pdbx_seq_one_letter_code\n",
    "                        seq_one_letter_code=search_peptide_seq_one_letter_code(cif_data,entity_id)\n",
    "                        if seq_one_letter_code != None:\n",
    "                            if seq_one_letter_code not in ligands: ligands.append(seq_one_letter_code)\n",
    "                        else:\n",
    "                            if i[3] not in ligands: ligands.append(i[3])\n",
    "                \n",
    "            else:\n",
    "                if check_polypeptide(cif_data, entity_id) == 'Yes': # Only 'polypeptide(L)' polymers are considered as the main polymers of the structure\n",
    "                    chain.append(search_asym_id(cif_data,entity_id))  # chain is the asym_id of the polymers that are not ligands\n",
    "                    pols.append(i[3])\n",
    "                    seq = search_peptide_seq_one_letter_code_can(cif_data,entity_id)\n",
    "                    num_res.append(str(len(seq)))\n",
    "\n",
    "                    mismatches, mismatch_location, identity, gaps = (None, None, None, None)\n",
    "                    if mutation == True:\n",
    "                        mismatches, mismatch_location, identity, gaps = search_for_mutation(seq_ref,seq)  # Ho pot diverses vegades, depen del nombre entity_ids, pero nomes es queda amb el darrer resultat\n",
    "\n",
    "                    #print(pdb_id, entity_id, mismatches, mismatch_location, identity, gaps)\n",
    "\n",
    "        elif i[1] == 'non-polymer': # non-polymer could be ligands or small-molecules from the medium\n",
    "            ligand_code=search_ligand_code(cif_data,entity_id) # From the entity_id, search the ligand_code or sequence (for peptides without a code)\n",
    "            if ligand_code not in blacklist: # Only molecules not present in the blacklist file are considered as ligands\n",
    "                ligands.append(ligand_code)\n",
    "                ligand_names.append(i[3])\n",
    "                asym_id=search_asym_id(cif_data,entity_id)\n",
    "                for id_a in asym_id.split(','):\n",
    "                    covalent_bond=check_covalent(cif_data,id_a)\n",
    "                    if covalent_bond:\n",
    "                        covalent='Yes'\n",
    "                        bond=covalent_bond\n",
    "    \n",
    "    chain=','.join(chain) # We join all the chains\n",
    "    nchain=chain.count(',')+1\n",
    "    num_res=', '. join(num_res)\n",
    "    ligand_names='\\n'. join(ligand_names)\n",
    "    pols='\\n'.join(pols)\n",
    "\n",
    "    if not ligands: complex='No'\n",
    "    else: complex ='Yes'\n",
    "\n",
    "    ligands='\\n'.join(ligands)\n",
    "    if mutation == True:\n",
    "        mismatch_location = ', '.join(mismatch_location)\n",
    "    else:\n",
    "        mismatch_location = None\n",
    "        \n",
    "    return {\n",
    "        \"PDB_ID\": pdb_id,\n",
    "        \"Title\":title,\n",
    "        \"Protein_description\": pols,\n",
    "        \"NChain\":nchain,\n",
    "        \"Chain_ID\": chain,\n",
    "        \"Num_Res\": num_res,\n",
    "        \"Complex\": complex,\n",
    "        \"Ligand\": ligands,\n",
    "        \"Ligand names\": ligand_names,\n",
    "        \"Peptide_like\": peptide_like,\n",
    "        \"Covalent_Bond\": covalent,\n",
    "        \"Bond\": bond,\n",
    "        \"Mutation\": mismatches,\n",
    "        \"Mutation_Location\": mismatch_location,\n",
    "        \"Identity\": identity,\n",
    "        \"Gaps\": gaps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_classification(information_df, output_path):\n",
    "    \"\"\"\n",
    "    Classification based on the information contained in a dataframe. \n",
    "    Downloading PDB files into different folders depend whether there is a mutation.\n",
    "    \"\"\"\n",
    "       \n",
    "    mutated_list = []\n",
    "    no_mutated_list = []\n",
    "\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    with open(information_df, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Mutation'] == 0:\n",
    "                no_mutated_list.append(row['PDB_ID'])\n",
    "            else:\n",
    "                mutated_list.append(row['PDB_ID'])\n",
    "\n",
    "    origin_path = os.getcwd() +'/cif/'\n",
    "\n",
    "    mut_path = output_path + '/Mutated/'\n",
    "    if os.path.exists(mut_path):\n",
    "        mut_path = output_path + '/Mutated_' + current_datetime +'/'\n",
    "        os.makedirs(mut_path)\n",
    "    else: \n",
    "        os.makedirs(mut_path)\n",
    "\n",
    "    non_mut_path = output_path + '/Non-Mutated/'\n",
    "    if os.path.exists(non_mut_path):\n",
    "        non_mut_path = output_path + '/Non-Mutated_' + current_datetime + '/'\n",
    "        os.makedirs(non_mut_path)\n",
    "    else:\n",
    "        os.makedirs(non_mut_path)\n",
    "\n",
    "\n",
    "    for mutated in mutated_list:\n",
    "        pdb_id = mutated.lower()\n",
    "        shutil.copy(origin_path+(pdb_id+\".cif\"), mut_path+(pdb_id+\".cif\"))\n",
    "\n",
    "    for no_mutated in no_mutated_list:\n",
    "        pdb_id = no_mutated.lower()\n",
    "        shutil.copy(origin_path+(pdb_id+\".cif\"), non_mut_path +(pdb_id+\".cif\"))\n",
    "\n",
    "\n",
    "    return no_mutated_list, non_mut_path \n",
    "\n",
    "\n",
    "def bond_classification(information_df, no_mutated_list, output_path, mutation):\n",
    "    \"\"\"\n",
    "    This function classifies between free enzymes and complexes.\n",
    "    And for each complex, it classifies depending on their bonds: covalent or non-covalent.\n",
    "    \"\"\"\n",
    "\n",
    "    free_enzyme_list = []\n",
    "    covalent_list = []\n",
    "    non_covalent_list = []\n",
    "\n",
    "    with open(\"df.csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Complex'] == 'No':\n",
    "                if row['PDB_ID'] in no_mutated_list:\n",
    "                    free_enzyme_list.append(row['PDB_ID'])\n",
    "                    \n",
    "            else:\n",
    "                if row['PDB_ID'] in no_mutated_list:\n",
    "                    if row['Covalent_Bond'] == 'Yes':\n",
    "                        covalent_list.append(row['PDB_ID'])\n",
    "                    elif row['Covalent_Bond'] == 'No':\n",
    "                        non_covalent_list.append(row['PDB_ID'])\n",
    "\n",
    "    if mutation == False:\n",
    "        origin_path = os.getcwd() +'/cif/'\n",
    "    elif mutation == True:\n",
    "        origin_path = output_path\n",
    "\n",
    "    free_path = output_path  + 'Free/'\n",
    "    covalent_path = output_path  + 'Covalent/'\n",
    "    non_covalent_path = output_path + 'Non-Covalent/'\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for path in [free_path, covalent_path, non_covalent_path]:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    for free in free_enzyme_list:\n",
    "        pdb_id = free.lower() + \".cif\"\n",
    "        if mutation == True:\n",
    "            shutil.move(origin_path+(pdb_id), free_path+(pdb_id))\n",
    "        if mutation == False:\n",
    "            shutil.copy(origin_path+(pdb_id), free_path+(pdb_id))\n",
    "\n",
    "    for covalent in covalent_list:\n",
    "        pdb_id = covalent.lower() + \".cif\"\n",
    "        if mutation == True:\n",
    "            shutil.move(origin_path+(pdb_id), covalent_path+(pdb_id))\n",
    "        if mutation == False:\n",
    "            shutil.copy(origin_path+(pdb_id), covalent_path+(pdb_id))\n",
    "\n",
    "    for non_covalent in non_covalent_list:\n",
    "        pdb_id = non_covalent.lower() + \".cif\"\n",
    "        if mutation == True:\n",
    "            shutil.move(origin_path+(pdb_id), non_covalent_path+(pdb_id))\n",
    "        if mutation == False:\n",
    "            shutil.copy(origin_path+(pdb_id), non_covalent_path+(pdb_id))\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN CODE\n",
    "=========\n",
    "INITIAL INFORMATION. CHANGE THE CONTENT OF THESE VARIABLES IF NECESSARY\n",
    "\"\"\"\n",
    "\n",
    "directory_path =os.getcwd()+\"/cif/\"  # Path to the folder with the cif files to process\n",
    "out_file='' # Path and name of the csv output file\n",
    "mutation = True   # Analyze mutations. True or False\n",
    "output_path = ''\n",
    "pdb_reference_sequence = '' # Path to the pdb file that will be the reference sequence. \n",
    "entity_reference = 0 # '0' means that the first _entity_poly of the pdb_reference_sequence will be the reference sequence\n",
    "blacklist= read_blacklist(\"./blacklist.txt\") # Path to the blacklist file that contain the codes of the small molecules not considered ligands\n",
    "reference_seq=''\n",
    "\n",
    "# READ THE REFERENCE SEQUENCE. It is a PDB file in CIF format.\n",
    "if mutation == True:\n",
    "    ref_cfr = CifFileReader()\n",
    "    ref_cif_obj = ref_cfr.read(pdb_reference_sequence, output='cif_wrapper', ignore=['_atom_site'])\n",
    "    ref_cif_data = list(ref_cif_obj.values())[0]\n",
    "    if '_entity_poly' in ref_cif_data:\n",
    "        reference_seq = ref_cif_data['_entity_poly']['pdbx_seq_one_letter_code_can'][entity_reference]  \n",
    "        reference_seq = reference_seq.replace(\"\\n\",\"\")\n",
    "\n",
    "data = [] # It will contain the information for each PDB file\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.cif'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        data_from_file = process_cif_file(file_path, mutation, blacklist, reference_seq)\n",
    "        data.append(data_from_file)\n",
    "        \n",
    "df = pd.DataFrame(data) # Create a Pandas df\n",
    "# Muestra el DataFrame\n",
    "df.to_csv(out_file, index=False) # Save the df into a file\n",
    "        \n",
    "# Classification\n",
    "if mutation == False:\n",
    "    no_mutated_list = os.listdir(directory_path)\n",
    "    no_mutated_list = [filename[:-4].upper() for filename in no_mutated_list]\n",
    "\n",
    "if mutation ==True:    \n",
    "    # Classify whether there is a mutation\n",
    "    no_mutated_list, non_mut_path = mutation_classification(\"df.csv\", output_path)\n",
    "    output_path = non_mut_path \n",
    "\n",
    "# Classify depend on the bond\n",
    "bond_classification(\"df.csv\", no_mutated_list, output_path, mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
